---
title: "Simulationsstudie"
author: "Xuan Son Le (4669361)"
date: "10/7/2018"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)  
library(dplyr)
library(ggplot2)
library(xtable)
library(Hmisc)
library(params)
library(gridExtra)
library(caret)
library(caTools)
library(nnet)
library(e1071)
library(scales)
library(pROC)
library(stringr)
library(rgdal)
library(gpclib)
#library(rgeos)
library(maptools)
options(xtable.floating = FALSE)
options(xtable.timestamp = "")
```

```{r Simulation Szenario 1}
# Daten generieren
source('./Simulationsdaten/simpleSzenario.R')

# SVM Parameteroptimierung anhand einem Paar Sample - Population
trainDF <- popList[[1]]$smp
validDF <- popList[[1]]$pop

S1_linSVM_Tune <- tune.svm(y ~ X_1 + X_2, data = trainDF, kernel = 'linear',
             cost = 10^(c(-6:2)))

S1_RBFSVM_Tune <- tune.svm(y ~ X_1 + X_2, data = trainDF,
             gamma = 10^(c(-2:5)),
             cost = 10^(c(-2:5)))

summary(S1_linSVM_Tune)

# MLR und SVM für jedes Paar Sample - Population
S1_MLR_Accuracy <- data.frame(Fold = integer(), Accuracy = integer())
S1_linSVM_Accuracy <- data.frame(Fold = integer(), Accuracy = integer())
S1_RBFSVM_Accuracy <- data.frame(Fold = integer(), Accuracy = integer())

S1_MLR_ConfMat <- list()
S1_linSVM_ConfMat <- list()
S1_RBFSVM_ConfMat <- list()

for (i in c(1:simRuns)) {
    # Trainings- und Validierungsdaten
    trainDF <- popList[[i]]$smp # Sample als Trainingsdaten
    validDF <- popList[[i]]$pop # Population als Validierungsdaten
    
    trainDF$y <- factor(trainDF$y)
    validDF$y <- factor(validDF$y)
    
    # S1_linSVM_Tune <- tune.svm(y ~ X_1 + X_2, data = trainDF, kernel = 'linear',
    #              cost = 10^(c(-3:3)))
    # 
    # S1_RBFSVM_Tune <- tune.svm(y ~ X_1 + X_2, data = trainDF,
    #              gamma = 10^(c(-3:3)),
    #              cost = 10^(c(-3:3)))

    # MLR Trainieren
    S1_MLR_FULL <- multinom(y ~ X_1 + X_2, data = trainDF)
    S1_MLR_AIC <- step(S1_MLR_FULL, direction = 'backward', trace = 0)
    # MLR Vorhersagen
    S1_MLR_yPred <- predict(S1_MLR_AIC, newdata = validDF[-1])
    # MLR Confusion Matrix
    S1_MLR_ConfMat = table(true = validDF[,1], pred = S1_MLR_yPred)
    # MLR Genauigkeit
    S1_MLR_Accuracy[i,] <- c(i, sum(diag(S1_MLR_ConfMat))/sum(S1_MLR_ConfMat))
    
    # linSVM Trainieren
    S1_linSVM_Modell <- svm(y ~ X_1 + X_2,
                  data = trainDF,
                  type = "C-classification",
                  kernel = "radial",
                  cost = S1_linSVM_Tune$best.parameters$cost,
                  probability = TRUE)
    # linSVM Vorhersage
    S1_linSVM_yPred = predict(S1_linSVM_Modell, newdata = validDF[-1])
    # linSVM Confusion Matrix
    S1_linSVM_ConfMat = table(true = validDF[,1], pred = S1_linSVM_yPred)
    # linSVM Genauigkeit
    S1_linSVM_Accuracy[i,] <- c(i,sum(diag(S1_linSVM_ConfMat))/sum(S1_linSVM_ConfMat))
    
    # RBFSVM Trainieren
    S1_RBFSVM_Modell <- svm(y ~ X_1 + X_2,
                  data = trainDF,
                  type = "C-classification",
                  kernel = "radial",
                  gamma = S1_RBFSVM_Tune$best.parameters$gamma, 
                  cost = S1_RBFSVM_Tune$best.parameters$cost,
                  probability = TRUE)
    # RBFSVM Vorhersage
    S1_RBFSVM_yPred = predict(S1_RBFSVM_Modell, newdata = validDF[-1])
    # RBFSVM Confusion Matrix
    S1_RBFSVM_ConfMat = table(true = validDF[,1], pred = S1_RBFSVM_yPred)
    # RBFSVM Genauigkeit
    S1_RBFSVM_Accuracy[i,] <- c(i,sum(diag(S1_RBFSVM_ConfMat))/sum(S1_RBFSVM_ConfMat))
   
}

S1_Accuracy <- data.frame(Accuracy = c(S1_MLR_Accuracy$Accuracy,
                                       S1_linSVM_Accuracy$Accuracy,
                                       S1_RBFSVM_Accuracy$Accuracy),
                          ID = c(rep("MLR", simRuns), 
                                 rep("linSVM", simRuns), 
                                 rep("RBFSVM", simRuns)))

abb610 <- ggplot(S1_Accuracy, aes(x = ID, y = Accuracy, color = ID)) + 
    geom_boxplot() +
    theme_light() +
    scale_x_discrete(limits = c('MLR', 'linSVM', 'RBFSVM')) +
    #scale_y_continuous(limits = c(min(S2_Accuracy$Accuracy), max(S2_Accuracy$Accuracy))) +
    scale_color_discrete(guide = FALSE) +
    theme(#plot.title = element_text(size = 28, face = "bold"),
          axis.line.x = element_line(color = "black", size = 0.5),
          axis.line.y = element_line(color = "black", size = 0.5),
          axis.text.x = element_text(size = 20, margin = margin(t = 5, r = 0, b = 10, l = 0)),
          axis.text.y = element_text(size = 20, margin = margin(t = 0, r = 0, b = 0, l = 10)),
          #axis.title.x = element_text(size = 24, face = "bold"),
          axis.title.x = element_blank(),
          axis.title.y = element_text(size = 24, face = "bold"),
          axis.ticks.length = unit(.25, "cm"),
          axis.ticks = element_line(colour = "black"),
          legend.title = element_blank())

ggsave(plot = abb610, filename = "./Abbildungen/Abbildung_6_10.pdf", width = 297, height = 210, units = "mm")
```

```{r Simulation Szenario 2}
load("/Users/XuanSon/Desktop/complexSimData.Rdata")

# SVM Parameteroptimierung anhand einem Paar Sample - Population
trainDF <- popList[[1]]$smp
validDF <- popList[[1]]$pop

S2_linSVM_Tune <- tune.svm(y ~ . - intecept , data = trainDF, kernel = 'linear',
             cost = 10^(c(-3:3)))

S2_RBFSVM_Tune <- tune.svm(y ~ . - intecept, data = trainDF,
             gamma = 10^(c(-3:3)),
             cost = 10^(c(-3:3)))

# S2_polySVM_Tune <- tune.svm(y ~ . - intecept, data = trainDF, kernel = 'polynomial', 
#              gamma = 10^(c(-3:3)),
#              coef0 = 10^(c(1:3)),
#              degree = 2:5,
#              cost = 10^(c(-3:3))
#              )

S2_sigSVM_Tune <- tune.svm(y ~ . - intecept, data = trainDF, kernel = 'sigmoid',
             gamma = 10^(c(-5:3)),
             coef0 = 10^(c(-5:3)),
             cost = 10^(c(-3:3))
             )

# MLR und SVM für jedes Paar Sample - Population
S2_MLR_Accuracy <- data.frame(Fold = integer(), Accuracy = integer())
S2_linSVM_Accuracy <- data.frame(Fold = integer(), Accuracy = integer())
S2_RBFSVM_Accuracy <- data.frame(Fold = integer(), Accuracy = integer())
S2_sigSVM_Accuracy <- data.frame(Fold = integer(), Accuracy = integer())

# S1_MLR_RmVar <- data.frame(Fold = integer(), rmVar = integer())
# S1_linSVM_RmVar <- data.frame(Fold = integer(), rmVar = integer())
# S1_RBFSVM_RmVar <- data.frame(Fold = integer(), rmVar = integer())

S2_MLR_ConfMat <- list()
S2_linSVM_ConfMat <- list()
S2_RBFSVM_ConfMat <- list()
S2_sigSVM_ConfMat <- list()

for (i in c(1:200)) {
    # Trainings- und Validierungsdaten
    trainDF <- popList[[i]]$smp # Sample als Trainingsdaten
    validDF <- popList[[i]]$pop # Population als Validierungsdaten
    
    trainDF[,c('y', 'X_5', 'X_6')] <- lapply(trainDF[,c('y', 'X_5', 'X_6')],
                                             function(x) factor(x))
    validDF[,c('y', 'X_5', 'X_6')] <- lapply(validDF[,c('y', 'X_5', 'X_6')],
                                             function(x) factor(x))
    
    # MLR Trainieren
    S2_MLR_FULL <- multinom(y ~ . - intecept, data = trainDF)
    S2_MLR_AIC <- step(S2_MLR_FULL, direction = 'backward', trace = 0)
    # MLR Vorhersagen
    S2_MLR_yPred <- predict(S2_MLR_AIC, newdata = validDF[-1])
    # MLR Confusion Matrix
    S2_MLR_ConfMat = table(true = validDF[,1], pred = S2_MLR_yPred)
    # MLR Genauigkeit
    S2_MLR_Accuracy[i,] <- c(i, sum(diag(S2_MLR_ConfMat))/sum(S2_MLR_ConfMat))
    
    # linSVM Trainieren
    S2_linSVM_Modell <- svm(y ~ . - intecept,
                  data = trainDF,
                  type = "C-classification",
                  kernel = "radial",
                  cost = S2_linSVM_Tune$best.parameters$cost)
    # linSVM Vorhersage
    S2_linSVM_yPred = predict(S2_linSVM_Modell, newdata = validDF[-1])
    # linSVM Confusion Matrix
    S2_linSVM_ConfMat = table(true = validDF[,1], pred = S2_linSVM_yPred)
    # linSVM Genauigkeit
    S2_linSVM_Accuracy[i,] <- c(i,sum(diag(S2_linSVM_ConfMat))/sum(S2_linSVM_ConfMat))
    
    # RBFSVM Trainieren
    S2_RBFSVM_Modell <- svm(y ~ . - intecept,
                  data = trainDF,
                  type = "C-classification",
                  kernel = "radial",
                  gamma = S2_RBFSVM_Tune$best.parameters$gamma, 
                  cost = S2_RBFSVM_Tune$best.parameters$cost)
    # RBFSVM Vorhersage
    S2_RBFSVM_yPred = predict(S2_RBFSVM_Modell, newdata = validDF[-1])
    # RBFSVM Confusion Matrix
    S2_RBFSVM_ConfMat = table(true = validDF[,1], pred = S2_RBFSVM_yPred)
    # RBFSVM Genauigkeit
    S2_RBFSVM_Accuracy[i,] <- c(i,sum(diag(S2_RBFSVM_ConfMat))/sum(S2_RBFSVM_ConfMat))
   
    # sigSVM Trainieren
    S2_sigSVM_Modell <- svm(y ~ . - intecept,
                  data = trainDF,
                  type = "C-classification",
                  kernel = "sigmoid",
                  cost = S2_sigSVM_Tune$best.parameters$cost,
                  gamma = S2_sigSVM_Tune$best.parameters$gamma,
                  coef0 = S2_sigSVM_Tune$best.parameters$coef0)
    # sigSVM Vorhersage
    S2_sigSVM_yPred = predict(S2_sigSVM_Modell, newdata = validDF[-1])
    # sigSVM Confusion Matrix
    S2_sigSVM_ConfMat = table(true = validDF[,1], pred = S2_sigSVM_yPred)
    # sigSVM Genauigkeit
    S2_sigSVM_Accuracy[i,] <- c(i,sum(diag(S2_sigSVM_ConfMat))/sum(S2_sigSVM_ConfMat))
}

S2_Accuracy <- data.frame(Accuracy = c(S2_MLR_Accuracy$Accuracy,
                                       S2_linSVM_Accuracy$Accuracy,
                                       S2_RBFSVM_Accuracy$Accuracy,
                                       S2_sigSVM_Accuracy$Accuracy),
                          ID = c(rep("MLR", 200), 
                                 rep("linSVM", 200),
                                 rep("RBFSVM", 200),
                                 rep("sigSVM", 200)))

abb611 <- ggplot(S2_Accuracy, aes(x = ID, y = Accuracy, color = ID)) + 
    geom_boxplot() +
    theme_light() +
    scale_x_discrete(limits = c('MLR', 'linSVM', 'RBFSVM', 'sigSVM')) +
    #scale_y_continuous(limits = c(min(S2_Accuracy$Accuracy), max(S2_Accuracy$Accuracy))) +
    scale_color_discrete(guide = FALSE) +
    theme(#plot.title = element_text(size = 28, face = "bold"),
          axis.line.x = element_line(color = "black", size = 0.5),
          axis.line.y = element_line(color = "black", size = 0.5),
          axis.text.x = element_text(size = 20, margin = margin(t = 5, r = 0, b = 10, l = 0)),
          axis.text.y = element_text(size = 20, margin = margin(t = 0, r = 0, b = 0, l = 10)),
          #axis.title.x = element_text(size = 24, face = "bold"),
          axis.title.x = element_blank(),
          axis.title.y = element_text(size = 24, face = "bold"),
          axis.ticks.length = unit(.25, "cm"),
          axis.ticks = element_line(colour = "black"),
          legend.title = element_blank())

ggsave(plot = abb611, filename = "./Abbildungen/Abbildung_6_11a.pdf", width = 297, height = 210, units = "mm")

```