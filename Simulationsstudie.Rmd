---
title: "Simulationsstudie"
author: "Xuan Son Le (4669361)"
date: "10/7/2018"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r Setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)  
library(dplyr)
library(ggplot2)
library(xtable)
library(Hmisc)
library(params)
library(gridExtra)
library(caret)
library(caTools)
library(nnet)
library(e1071)
options(xtable.floating = FALSE)
options(xtable.timestamp = "")
```

```{r Szenario 1}
# Daten generieren
source('./Simulationsdaten/simpleSzenario.R')

# SVM Parameteroptimierung anhand einem Paar Sample - Population
trainDF <- popList[[26]]$smp
validDF <- popList[[26]]$pop

# Zielvariable faktorisieren
trainDF$y <- as.factor(trainDF$y)
validDF$y <- as.factor(validDF$y)

# Interzept entfernen
trainDF <- trainDF[,-2]
validDF <- validDF[,-2]

S1_linSVM_Tune <- tune.svm(y ~ ., data = trainDF, 
                           kernel = 'linear',
                           cost = 10^(c(-6:3)))


S1_RBFSVM_Tune <- tune.svm(y ~ ., data = trainDF,
                           kernel = 'radial',
                           gamma = 10^(c(-2:5)),
                           cost = 10^(c(-2:5)))


# Modellierung für Szenario 1 starten
S1_MLR_Accuracy <- data.frame(Fold = integer(), Accuracy = integer())
S1_linSVM_Accuracy <- data.frame(Fold = integer(), Accuracy = integer())
S1_RBFSVM_Accuracy <- data.frame(Fold = integer(), Accuracy = integer())

S1_MLR_ConfMat <- list()
S1_linSVM_ConfMat <- list()
S1_RBFSVM_ConfMat <- list()

S1_MLR_AUC <- matrix(NA, nrow = 200, ncol = 4)
S1_linSVM_AUC <- matrix(NA, nrow = 200, ncol = 4)
S1_RBFSVM_AUC <- matrix(NA, nrow = 200, ncol = 4)

# MLR und SVM für jedes Paar Sample - Population
for (i in c(1:200)) {
    
    # Trainings- und Validierungsdaten
    trainDF <- popList[[i]]$smp # Sample als Trainingsdaten
    validDF <- popList[[i]]$pop # Population als Validierungsdaten
    
    # Zielvariable faktorisieren
    trainDF$y <- factor(trainDF$y)
    validDF$y <- factor(validDF$y)
    
    # Interzept wird entfernt
    trainDF <- trainDF[-2]
    validDF <- validDF[-2]

    # MLR Trainieren
    S1_MLR_FULL <- multinom(y ~ X_1 + X_2, data = trainDF)
    S1_MLR_AIC <- step(S1_MLR_FULL, direction = 'backward', trace = 0)
    # MLR Vorhersagen
    S1_MLR_yPred <- predict(S1_MLR_AIC, newdata = validDF[-1])
    S1_MLR_yProbPred <- predict(S1_MLR_AIC, newdata = validDF[-1], type = "probs")
    #all(as.numeric(S1_MLR_yPred) == apply(S1_MLR_yProbPred, 1, function(x) which.max(x)))
    # MLR Confusion Matrix
    S1_MLR_ConfMat = table(true = validDF[,1], pred = S1_MLR_yPred)
    # MLR Genauigkeit
    S1_MLR_Accuracy[i,] <- c(i, sum(diag(S1_MLR_ConfMat))/sum(S1_MLR_ConfMat))
    
    # linSVM Trainieren
    S1_linSVM_Modell <- svm(y ~ X_1 + X_2,
                  data = trainDF,
                  type = "C-classification",
                  kernel = "linear",
                  cost = 0.1,
                  probability = TRUE)
    # linSVM Vorhersage
    S1_linSVM_yPred = predict(S1_linSVM_Modell, newdata = validDF[-1])
    # linSVM Wahrscheinlichkeit vorhersagen
    S1_linSVM_yProbPred <- predict(S1_linSVM_Modell, newdata = validDF[-1], probability = TRUE)
    S1_linSVM_yProbPred <- attr(S1_linSVM_yProbPred, 'probabilities')
    S1_linSVM_yProbPred <- S1_linSVM_yProbPred[ , c("1","2","3","4")] 
    # linSVM Confusion Matrix
    S1_linSVM_ConfMat = table(true = validDF[,1], pred = S1_linSVM_yPred)
    # linSVM Genauigkeit
    S1_linSVM_Accuracy[i,] <- c(i,sum(diag(S1_linSVM_ConfMat))/sum(S1_linSVM_ConfMat))
    
    # RBFSVM Trainieren
    str(validDF)
    S1_RBFSVM_Modell <- svm(y ~ X_1 + X_2,
                  data = trainDF,
                  type = "C-classification",
                  kernel = "radial",
                  gamma = 0.01, 
                  cost = 10,
                  probability = TRUE)
    # RBFSVM Vorhersage
    S1_RBFSVM_yPred = predict(S1_RBFSVM_Modell, newdata = validDF[-1])
    # RBFSVM Wahrscheinlichkeit Vorhersage
    S1_RBFSVM_yProbPred = predict(S1_RBFSVM_Modell, newdata = validDF[-1], probability = TRUE)
    S1_RBFSVM_yProbPred <- attr(S1_RBFSVM_yProbPred, 'probabilities')
    S1_RBFSVM_yProbPred <- S1_RBFSVM_yProbPred[ , c("1","2","3","4")] 
    # RBFSVM Confusion Matrix
    S1_RBFSVM_ConfMat = table(true = validDF[,1], pred = S1_RBFSVM_yPred)
    # RBFSVM Genauigkeit
    S1_RBFSVM_Accuracy[i,] <- c(i,sum(diag(S1_RBFSVM_ConfMat))/sum(S1_RBFSVM_ConfMat))
    
}

#mean(S1_MLR_AUC)

# Box-Plot Genauigkeit
S1_Accuracy <- data.frame(Accuracy = c(S1_MLR_Accuracy$Accuracy,
                                       S1_linSVM_Accuracy$Accuracy,
                                       S1_RBFSVM_Accuracy$Accuracy),
                          ID = c(rep("MLR", 200), 
                                 rep("linSVM", 200), 
                                 rep("RBFSVM", 200)))

abb610 <- ggplot(S1_Accuracy, aes(x = ID, y = Accuracy, color = ID)) + 
    geom_boxplot(lwd = 1.4) +
    theme_light() +
    labs(y = "Genauigkeit") + 
    scale_x_discrete(limits = c('MLR', 'linSVM', 'RBFSVM')) +
    scale_y_continuous(limits = c(0.5, 0.65)) +
    scale_color_discrete(guide = FALSE) +
    theme(#plot.title = element_text(size = 28, face = "bold"),
          axis.line.x = element_line(color = "black", size = 0.5),
          axis.line.y = element_line(color = "black", size = 0.5),
          axis.text.x = element_text(size = 20, margin = margin(t = 5, r = 0, b = 10, l = 0), face = "bold"),
          axis.text.y = element_text(size = 20, margin = margin(t = 0, r = 0, b = 0, l = 10)),
          #axis.title.x = element_text(size = 24, face = "bold"),
          axis.title.x = element_blank(),
          axis.title.y = element_text(size = 24, face = "bold"),
          axis.ticks.length = unit(.25, "cm"),
          axis.ticks = element_line(colour = "black"),
          legend.title = element_blank())

ggsave(plot = abb610, filename = "./Abbildungen/Abbildung_7_1_a.pdf", width = 297, height = 210, units = "mm")
```

```{r Szenario 2}
# complexSimData.Rdata wird eingelesen
load("./complexSimData.Rdata")

# SVM Parameteroptimierung anhand einem Paar Sample - Population
trainDF <- popList[[26]]$smp
validDF <- popList[[26]]$pop

# Zielvariable & 2 binäre erklärende Variablen faktorisieren
trainDF[,c('y', 'X_5', 'X_6')] <- lapply(trainDF[,c('y', 'X_5', 'X_6')],
                                         function(x) factor(x))
validDF[,c('y', 'X_5', 'X_6')] <- lapply(validDF[,c('y', 'X_5', 'X_6')],
                                         function(x) factor(x))

# Interzept entfernen
trainDF <- trainDF[,-2]
validDF <- validDF[,-2]
# 
# S2_linSVM_Tune <- tune.svm(y ~ ., data = trainDF, 
#                            kernel = 'linear',
#                            cost = 10^(c(-6:3)))
# 
# S2_RBFSVM_Tune <- tune.svm(y ~ ., data = trainDF,
#                            kernel = 'radial',
#                            gamma = 10^(c(-2:5)),
#                            cost = 10^(c(-2:5)))
# 
# S2_linSVM_TuneErgebnisse <- data.frame(C = S2_linSVM_Tune$performances[,1], 
#                                        Accuracy = 1 - S2_linSVM_Tune$performances[,2])
# 
# S2_RBFSVM_TuneErgebnisse <- data.frame(Gamma = S2_RBFSVM_Tune$performances[,1],
#                                        C = S2_RBFSVM_Tune$performances[,2],
#                                        Accuracy = 1 - S2_RBFSVM_Tune$performances[,3])
# 
# write.csv(S2_linSVM_TuneErgebnisse, "./CSV-Ergebnisse/S2_linSVM_Tune.csv")
# write.csv(S2_RBFSVM_TuneErgebnisse, "./CSV-Ergebnisse/S2_RBFSVM_Tune.csv")

S2_optimalLinSVMCost <- 1
S2_optimalRBFSVMGamma <- 0.01
S2_optimalRBFSVMCost <- 100

# MLR Trainieren
S2_MLR_FULL <- multinom(y ~ ., data = trainDF)
S2_MLR_AIC <- step(S2_MLR_FULL, direction = 'backward', trace = 0)
# MLR Vorhersagen
S2_MLR_yPred <- predict(S2_MLR_AIC, newdata = validDF[-1])
S2_MLR_yProbPred <- predict(S2_MLR_AIC, newdata = validDF[-1], type = "probs")
S2_MLR_ConfMat = table(true = validDF[,1], pred = S2_MLR_yPred)
S2_MLR_Accuracy <- round(sum(diag(S2_MLR_ConfMat))*100/sum(S2_MLR_ConfMat),2)
# all(as.numeric(S2_MLR_yPred) == apply(S2_MLR_yProbPred, 1, function(x) which.max(x)))
# xtable(S2_MLR_ConfMat)

# linSVM Trainieren
S2_linSVM_Modell <- svm(y ~ .,
                        data = trainDF,
                        type = "C-classification",
                        kernel = "linear",
                        cost = S2_optimalLinSVMCost,
                        probability = TRUE)
# linSVM Vorhersage
S2_linSVM_yPred = predict(S2_linSVM_Modell, newdata = validDF[-1])
# linSVM Wahrscheinlichkeit vorhersagen
S2_linSVM_yProbPred <- predict(S2_linSVM_Modell, newdata = validDF[-1], probability = TRUE)
S2_linSVM_yProbPred <- attr(S2_linSVM_yProbPred, 'probabilities')
S2_linSVM_yProbPred <- S2_linSVM_yProbPred[ , c("1","2","3","4")] 
S2_linSVM_ConfMat = table(true = validDF[,1], 
                          pred = apply(S2_linSVM_yProbPred, 1, function(x) which.max(x)))
S2_linSVM_Accuracy <- round(sum(diag(S2_linSVM_ConfMat))*100/sum(S2_linSVM_ConfMat),2)
# sum(as.numeric(S2_linSVM_yPred) == apply(S2_linSVM_yProbPred, 1, function(x) which.max(x)))
# xtable(S2_linSVM_ConfMat)

# RBFSVM Trainieren
S2_RBFSVM_Modell <- svm(y ~ .,
                        data = trainDF,
                        type = "C-classification",
                        kernel = "radial",
                        gamma = S2_optimalRBFSVMGamma, 
                        cost = S2_optimalRBFSVMCost,
                        probability = TRUE)
# RBFSVM Vorhersage
S2_RBFSVM_yPred = predict(S2_RBFSVM_Modell, newdata = validDF[-1])
# RBFSVM Wahrscheinlichkeit Vorhersage
S2_RBFSVM_yProbPred = predict(S2_RBFSVM_Modell, newdata = validDF[-1], probability = TRUE)
S2_RBFSVM_yProbPred <- attr(S2_RBFSVM_yProbPred, 'probabilities')
S2_RBFSVM_yProbPred <- S2_RBFSVM_yProbPred[ , c("1","2","3","4")] 
S2_RBFSVM_ConfMat = table(true = validDF[,1], 
                          pred = apply(S2_RBFSVM_yProbPred, 1, function(x) which.max(x)))
S2_RBFSVM_Accuracy <- round(sum(diag(S2_RBFSVM_ConfMat))*100/sum(S2_RBFSVM_ConfMat),2)
# xtable(S2_RBFSVM_ConfMat)

# Beispielshafte ROC
# Transformiere die Zielvariable in Dummy-Variablen (in Populationsdaten)
S2_dummyDF <- matrix(nrow = nrow(validDF), ncol = nlevels(validDF$y))

for (i in c(1:nlevels(validDF$y))) {
    S2_dummyDF[,i] <- as.numeric(validDF[1] == i)
    
}
rm(i)

S2_MLR_ROC_1 <- roc(S2_dummyDF[,1], S2_MLR_yProbPred[,1])
S2_MLR_ROC_2 <- roc(S2_dummyDF[,2], S2_MLR_yProbPred[,2])
S2_MLR_ROC_3 <- roc(S2_dummyDF[,3], S2_MLR_yProbPred[,3])
S2_MLR_ROC_4 <- roc(S2_dummyDF[,4], S2_MLR_yProbPred[,4])

S2_MLR_AUC <- round(as.numeric(lapply(list(S2_MLR_ROC_1,S2_MLR_ROC_2,
                                           S2_MLR_ROC_3,S2_MLR_ROC_4),
                                      function(x) auc(x))),4)
S2_MLR_AUC_Mean <- round(mean(S2_MLR_AUC),4)

S2_linSVM_ROC_1 <- roc(S2_dummyDF[,1], S2_linSVM_yProbPred[,1])
S2_linSVM_ROC_2 <- roc(S2_dummyDF[,2], S2_linSVM_yProbPred[,2])
S2_linSVM_ROC_3 <- roc(S2_dummyDF[,3], S2_linSVM_yProbPred[,3])
S2_linSVM_ROC_4 <- roc(S2_dummyDF[,4], S2_linSVM_yProbPred[,4])

S2_linSVM_AUC <- round(as.numeric(lapply(list(S2_linSVM_ROC_1,S2_linSVM_ROC_2,
                                              S2_linSVM_ROC_3, S2_linSVM_ROC_4), 
                                         function(x) auc(x))),4)
S2_linSVM_AUC_Mean <- mean(S2_linSVM_AUC)

S2_RBFSVM_ROC_1 <- roc(S2_dummyDF[,1], S2_RBFSVM_yProbPred[,1])
S2_RBFSVM_ROC_2 <- roc(S2_dummyDF[,2], S2_RBFSVM_yProbPred[,2])
S2_RBFSVM_ROC_3 <- roc(S2_dummyDF[,3], S2_RBFSVM_yProbPred[,3])
S2_RBFSVM_ROC_4 <- roc(S2_dummyDF[,4], S2_RBFSVM_yProbPred[,4])

S2_RBFSVM_AUC <- round(as.numeric(lapply(list(S2_RBFSVM_ROC_1,S2_RBFSVM_ROC_2,
                                              S2_RBFSVM_ROC_3, S2_RBFSVM_ROC_4), 
                                         function(x) auc(x))),4)
S2_RBFSVM_AUC_Mean <- mean(S2_RBFSVM_AUC)

S2_MLR_ROC <- ggroc(list(S2_MLR_ROC_1,S2_MLR_ROC_2,S2_MLR_ROC_3,S2_MLR_ROC_4), 
                    size = 1.5, legacy.axes = TRUE) +
    theme_light() + geom_abline(slope = 1, intercept = 0, size = 1) +
    labs(#title = "MLR",
        y = "Richtig-Positiv-Rate",
        x = "Falsch-Positiv-Rate") + 
    scale_color_discrete("y",
                         breaks = c("1", "2", "3", "4")) + 
    coord_fixed() +
    theme(#plot.title = element_text(size = 24, face = "bold"),
        axis.line.x = element_line(color = "black", size = 0.5),
        axis.line.y = element_line(color = "black", size = 0.5),
        axis.text.x = element_text(size = 20, margin = margin(t = 5, r = 0, b = 20, l = 0)),
        axis.text.y = element_text(size = 20, margin = margin(t = 0, r = 0, b = 0, l = 10)),
        axis.ticks.length = unit(.25, "cm"),
        axis.ticks = element_line(colour = "black"),
        axis.title.x = element_text(size = 24, face = "bold"),
        axis.title.y = element_text(size = 24, face = "bold"),
        legend.title = element_blank(),
        legend.margin = margin(c(0,10,0,0)),
        legend.text = element_text(size = 18),
        legend.position = "none",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        legend.box.margin = margin(c(5,0,5,0)),
        legend.key.width = unit(1.5,"line"),
        legend.key.height = unit(2,"line"),
        strip.text = element_text(colour = "black", size = 16)) +
    guides(color = guide_legend(nrow = 2)) 

ggsave(plot = S2_MLR_ROC, filename = "./Abbildungen/Abbildung_7_2_a.pdf", 
       width = 297, height = 210, units = "mm")

S2_linSVM_ROC <- ggroc(list(S2_linSVM_ROC_1,S2_linSVM_ROC_2,
                            S2_linSVM_ROC_3,S2_linSVM_ROC_4), 
                       size = 1.5, legacy.axes = TRUE) +
    theme_light() + geom_abline(slope = 1, intercept = 0, size = 1) +
    labs(y = "Richtig-Positiv-Rate",
         x = "Falsch-Positiv-Rate") + 
    scale_color_discrete("y",
                         breaks = c("1", "2", "3", "4"),
                         labels = c("y = 1\t", "y = 2\t", "y = 3\t", "y = 4\t")) + 
    coord_fixed() +
    theme(axis.line.x = element_line(color = "black", size = 0.5),
          axis.line.y = element_line(color = "black", size = 0.5),
          axis.text.x = element_text(size = 20, margin = margin(t = 5, r = 0, b = 20, l = 0)),
          axis.text.y = element_text(size = 20, margin = margin(t = 0, r = 0, b = 0, l = 10)),
          axis.ticks.length = unit(.25, "cm"),
          axis.ticks = element_line(colour = "black"),
          axis.title.x = element_text(size = 24, face = "bold"),
          axis.title.y = element_text(size = 24, face = "bold"),
          legend.title = element_blank(),
          legend.margin = margin(c(0,10,0,0)),
          legend.text = element_text(size = 18),
          legend.position = "none",
          legend.background = element_blank(),
          #legend.box.background = element_rect(colour = "black"),
          #legend.box.margin = margin(c(5,0,5,0)),
          legend.key.width = unit(1.5,"line"),
          legend.key.height = unit(2,"line"),
          strip.text = element_text(colour = "black", size = 16)) +
    guides(color = guide_legend(nrow = 1))

ggsave(plot = S2_linSVM_ROC, filename = "./Abbildungen/Abbildung_7_2_b.pdf", 
       width = 297, height = 210, units = "mm")


S2_RBFSVM_ROC <- ggroc(list(S2_RBFSVM_ROC_1,S2_RBFSVM_ROC_2,S2_RBFSVM_ROC_3,S2_RBFSVM_ROC_4),
                       size = 1.5, legacy.axes = TRUE) +
    theme_light() + geom_abline(slope = 1, intercept = 0, size = 1) +
    labs(y = "Richtig-Positiv-Rate",
         x = "Falsch-Positiv-Rate") + 
    scale_color_discrete("Armutskategorie",
                         breaks = c("1", "2", "3", "4")) + 
    coord_fixed() +
    theme(axis.line.x = element_line(color = "black", size = 0.5),
          axis.line.y = element_line(color = "black", size = 0.5),
          axis.text.x = element_text(size = 20, margin = margin(t = 5, r = 0, b = 20, l = 0)),
          axis.text.y = element_text(size = 20, margin = margin(t = 0, r = 0, b = 0, l = 10)),
          axis.ticks.length = unit(.25, "cm"),
          axis.ticks = element_line(colour = "black"),
          axis.title.x = element_text(size = 24, face = "bold"),
          axis.title.y = element_text(size = 24, face = "bold"),
          legend.title = element_blank(),
          legend.margin = margin(c(0,10,0,0)),
          legend.text = element_text(size = 18),
          legend.position = "none",
          legend.background = element_blank(),
          legend.box.background = element_rect(colour = "black"),
          legend.box.margin = margin(c(5,0,5,0)),
          legend.key.width = unit(1.5,"line"),
          legend.key.height = unit(2,"line"),
          strip.text = element_text(colour = "black", size = 16)) +
    guides(color = guide_legend(nrow = 2))

ggsave(plot = S2_RBFSVM_ROC, filename = "./Abbildungen/Abbildung_7_2_c.pdf", 
       width = 297, height = 210, units = "mm")

# Modellierung für Szenario 2 starten
# MLR und SVM für jedes Paar Sample - Population
S2_MLR_Accuracy <- data.frame(Fold = integer(), Accuracy = integer())
S2_linSVM_Accuracy <- data.frame(Fold = integer(), Accuracy = integer())
S2_RBFSVM_Accuracy <- data.frame(Fold = integer(), Accuracy = integer())

S2_MLR_ConfMat <- list()
S2_linSVM_ConfMat <- list()
S2_RBFSVM_ConfMat <- list()

for (i in c(1:200)) {
    # Trainings- und Validierungsdaten
    trainDF <- popList[[i]]$smp # Sample als Trainingsdaten
    validDF <- popList[[i]]$pop # Population als Validierungsdaten
    
    # Zielvariable faktorisieren
    trainDF$y <- factor(trainDF$y)
    validDF$y <- factor(validDF$y)
    
    # Interzept wird entfernt
    trainDF <- trainDF[-2]
    validDF <- validDF[-2]
    
    # MLR Trainieren
    S2_MLR_FULL <- multinom(y ~ ., data = trainDF)
    S2_MLR_AIC <- step(S2_MLR_FULL, direction = 'backward', trace = 0)
    # MLR Vorhersagen
    S2_MLR_yPred <- predict(S2_MLR_AIC, newdata = validDF[-1])
    S2_MLR_yProbPred <- predict(S2_MLR_AIC, newdata = validDF[-1], type = "probs")
    #all(as.numeric(S2_MLR_yPred) == apply(S2_MLR_yProbPred, 1, function(x) which.max(x)))
    # MLR Confusion Matrix
    S2_MLR_ConfMat = table(true = validDF[,1], pred = S2_MLR_yPred)
    # MLR Genauigkeit
    S2_MLR_Accuracy[i,] <- c(i, sum(diag(S2_MLR_ConfMat))/sum(S2_MLR_ConfMat))
    
    # linSVM Trainieren
    S2_linSVM_Modell <- svm(y ~ .,
                            data = trainDF,
                            type = "C-classification",
                            kernel = "linear",
                            cost = S2_optimalLinSVMCost,
                            probability = TRUE)
    # linSVM Vorhersage
    S2_linSVM_yPred = predict(S2_linSVM_Modell, newdata = validDF[-1])
    # linSVM Wahrscheinlichkeit vorhersagen
    S2_linSVM_yProbPred <- predict(S2_linSVM_Modell, newdata = validDF[-1], probability = TRUE)
    S2_linSVM_yProbPred <- attr(S2_linSVM_yProbPred, 'probabilities')
    S2_linSVM_yProbPred <- S2_linSVM_yProbPred[ , c("1","2","3","4")] 
    # linSVM Confusion Matrix
    S2_linSVM_ConfMat = table(true = validDF[,1], pred = S2_linSVM_yPred)
    # linSVM Genauigkeit
    S2_linSVM_Accuracy[i,] <- c(i,sum(diag(S2_linSVM_ConfMat))/sum(S2_linSVM_ConfMat))
    
    # RBFSVM Trainieren
    S2_RBFSVM_Modell <- svm(y ~ .,
                            data = trainDF,
                            type = "C-classification",
                            kernel = "radial",
                            gamma = S2_optimalRBFSVMGamma, 
                            cost = S2_optimalRBFSVMCost,
                            probability = TRUE)
    # RBFSVM Vorhersage
    S2_RBFSVM_yPred = predict(S2_RBFSVM_Modell, newdata = validDF[-1])
    # RBFSVM Wahrscheinlichkeit Vorhersage
    S2_RBFSVM_yProbPred = predict(S2_RBFSVM_Modell, newdata = validDF[-1], probability = TRUE)
    S2_RBFSVM_yProbPred <- attr(S2_RBFSVM_yProbPred, 'probabilities')
    S2_RBFSVM_yProbPred <- S2_RBFSVM_yProbPred[ , c("1","2","3","4")] 
    # RBFSVM Confusion Matrix
    S2_RBFSVM_ConfMat = table(true = validDF[,1], pred = S2_RBFSVM_yPred)
    # RBFSVM Genauigkeit
    S2_RBFSVM_Accuracy[i,] <- c(i,sum(diag(S2_RBFSVM_ConfMat))/sum(S2_RBFSVM_ConfMat))
    
}

S2_Accuracy <- data.frame(Accuracy = c(S2_MLR_Accuracy$Accuracy,
                                       S2_linSVM_Accuracy$Accuracy,
                                       S2_RBFSVM_Accuracy$Accuracy),
                          ID = c(rep("MLR", 200), 
                                 rep("linSVM", 200), 
                                 rep("RBFSVM", 200)))

abb71b <- ggplot(S2_Accuracy, aes(x = ID, y = Accuracy, color = ID)) + 
    geom_boxplot(lwd = 1.4) +
    theme_light() +
    labs(y = "Genauigkeit") + 
    scale_x_discrete(limits = c('MLR', 'linSVM', 'RBFSVM')) +
    scale_y_continuous(limits = c(0.50, 0.65)) +
    scale_color_discrete(guide = FALSE) +
    theme(#plot.title = element_text(size = 28, face = "bold"),
        axis.line.x = element_line(color = "black", size = 0.5),
        axis.line.y = element_line(color = "black", size = 0.5),
        axis.text.x = element_text(size = 20, margin = margin(t = 5, r = 0, b = 10, l = 0), face = "bold"),
        axis.text.y = element_text(size = 20, margin = margin(t = 0, r = 0, b = 0, l = 10)),
        #axis.title.x = element_text(size = 24, face = "bold"),
        axis.title.x = element_blank(),
        axis.title.y = element_text(size = 24, face = "bold"),
        axis.ticks.length = unit(.25, "cm"),
        axis.ticks = element_line(colour = "black"),
        legend.title = element_blank())

ggsave(plot = abb71b, filename = "./Abbildungen/Abbildung_7_1_b.pdf", width = 297, height = 210, units = "mm")

```